{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import unidecode\n",
    "import re\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------\n",
    "### Preparación del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder</th>\n",
       "      <th>path_audio</th>\n",
       "      <th>file</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C5N</td>\n",
       "      <td>../Data/Audio/C5N/C5N2020-08-14-17-55-49.wav</td>\n",
       "      <td>C5N2020-08-14-17-55-49.wav</td>\n",
       "      <td>2020-08-14 17:55:49</td>\n",
       "      <td>hola hola muy buenas tardes bienvenidos al dia...</td>\n",
       "      <td>2020-08-14 17:56:14</td>\n",
       "      <td>2020-08-14 17:56:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C5N</td>\n",
       "      <td>../Data/Audio/C5N/C5N2020-08-14-17-55-49.wav</td>\n",
       "      <td>C5N2020-08-14-17-55-49.wav</td>\n",
       "      <td>2020-08-14 17:55:49</td>\n",
       "      <td>tenemos que hablar de esta definición por part...</td>\n",
       "      <td>2020-08-14 17:56:34</td>\n",
       "      <td>2020-08-14 17:57:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C5N</td>\n",
       "      <td>../Data/Audio/C5N/C5N2020-08-14-17-55-49.wav</td>\n",
       "      <td>C5N2020-08-14-17-55-49.wav</td>\n",
       "      <td>2020-08-14 17:55:49</td>\n",
       "      <td>algún punto empieza a reconocer también y si u...</td>\n",
       "      <td>2020-08-14 17:57:19</td>\n",
       "      <td>2020-08-14 17:58:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C5N</td>\n",
       "      <td>../Data/Audio/C5N/C5N2020-08-14-17-55-49.wav</td>\n",
       "      <td>C5N2020-08-14-17-55-49.wav</td>\n",
       "      <td>2020-08-14 17:55:49</td>\n",
       "      <td>hay una circulación realmente muy alta como es...</td>\n",
       "      <td>2020-08-14 17:58:04</td>\n",
       "      <td>2020-08-14 17:58:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C5N</td>\n",
       "      <td>../Data/Audio/C5N/C5N2020-08-14-17-55-49.wav</td>\n",
       "      <td>C5N2020-08-14-17-55-49.wav</td>\n",
       "      <td>2020-08-14 17:55:49</td>\n",
       "      <td>en esta jornada tan importante hablamos de esp...</td>\n",
       "      <td>2020-08-14 17:58:50</td>\n",
       "      <td>2020-08-14 17:59:35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  folder                                    path_audio  \\\n",
       "0    C5N  ../Data/Audio/C5N/C5N2020-08-14-17-55-49.wav   \n",
       "1    C5N  ../Data/Audio/C5N/C5N2020-08-14-17-55-49.wav   \n",
       "2    C5N  ../Data/Audio/C5N/C5N2020-08-14-17-55-49.wav   \n",
       "3    C5N  ../Data/Audio/C5N/C5N2020-08-14-17-55-49.wav   \n",
       "4    C5N  ../Data/Audio/C5N/C5N2020-08-14-17-55-49.wav   \n",
       "\n",
       "                         file                 date  \\\n",
       "0  C5N2020-08-14-17-55-49.wav  2020-08-14 17:55:49   \n",
       "1  C5N2020-08-14-17-55-49.wav  2020-08-14 17:55:49   \n",
       "2  C5N2020-08-14-17-55-49.wav  2020-08-14 17:55:49   \n",
       "3  C5N2020-08-14-17-55-49.wav  2020-08-14 17:55:49   \n",
       "4  C5N2020-08-14-17-55-49.wav  2020-08-14 17:55:49   \n",
       "\n",
       "                                                text                start  \\\n",
       "0  hola hola muy buenas tardes bienvenidos al dia...  2020-08-14 17:56:14   \n",
       "1  tenemos que hablar de esta definición por part...  2020-08-14 17:56:34   \n",
       "2  algún punto empieza a reconocer también y si u...  2020-08-14 17:57:19   \n",
       "3  hay una circulación realmente muy alta como es...  2020-08-14 17:58:04   \n",
       "4  en esta jornada tan importante hablamos de esp...  2020-08-14 17:58:50   \n",
       "\n",
       "                   end  \n",
       "0  2020-08-14 17:56:33  \n",
       "1  2020-08-14 17:57:19  \n",
       "2  2020-08-14 17:58:04  \n",
       "3  2020-08-14 17:58:50  \n",
       "4  2020-08-14 17:59:35  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../Data procesada/data_audio.csv\")\n",
    "data.drop(columns=['Unnamed: 0'],inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "### Ventana temporal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['start'] = data['start'].apply(lambda x: datetime.datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))\n",
    "data['end'] = data['end'].apply(lambda x: datetime.datetime.strptime(x, '%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = 20\n",
    "td = datetime.timedelta(minutes=delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder</th>\n",
       "      <th>file</th>\n",
       "      <th>deltaStart</th>\n",
       "      <th>deltaEnd</th>\n",
       "      <th>deltaStep</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C5N</td>\n",
       "      <td>C5N2020-08-14-17-55-49</td>\n",
       "      <td>2020-08-14 17:56:14</td>\n",
       "      <td>2020-08-14 18:16:14</td>\n",
       "      <td>1</td>\n",
       "      <td>hola hola muy buenas tardes bienvenidos al dia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C5N</td>\n",
       "      <td>C5N2020-08-14-17-55-49</td>\n",
       "      <td>2020-08-14 18:16:14</td>\n",
       "      <td>2020-08-14 18:36:14</td>\n",
       "      <td>2</td>\n",
       "      <td>ellos saben que están pasando y se obligan a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C5N</td>\n",
       "      <td>C5N2020-08-14-17-55-49</td>\n",
       "      <td>2020-08-14 18:36:14</td>\n",
       "      <td>2020-08-14 18:56:14</td>\n",
       "      <td>3</td>\n",
       "      <td>de las camas respaldan por lo general faltan d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C5N</td>\n",
       "      <td>C5N2020-08-14-17-55-49</td>\n",
       "      <td>2020-08-14 18:56:14</td>\n",
       "      <td>2020-08-14 19:16:14</td>\n",
       "      <td>4</td>\n",
       "      <td>son altas área cama de star wars como creen qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C5N</td>\n",
       "      <td>C5N2020-08-14-17-55-49</td>\n",
       "      <td>2020-08-14 19:16:14</td>\n",
       "      <td>2020-08-14 19:36:14</td>\n",
       "      <td>5</td>\n",
       "      <td>se a manifestarse está claro que nadie quiere ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  folder                    file          deltaStart            deltaEnd  \\\n",
       "0    C5N  C5N2020-08-14-17-55-49 2020-08-14 17:56:14 2020-08-14 18:16:14   \n",
       "1    C5N  C5N2020-08-14-17-55-49 2020-08-14 18:16:14 2020-08-14 18:36:14   \n",
       "2    C5N  C5N2020-08-14-17-55-49 2020-08-14 18:36:14 2020-08-14 18:56:14   \n",
       "3    C5N  C5N2020-08-14-17-55-49 2020-08-14 18:56:14 2020-08-14 19:16:14   \n",
       "4    C5N  C5N2020-08-14-17-55-49 2020-08-14 19:16:14 2020-08-14 19:36:14   \n",
       "\n",
       "  deltaStep                                               text  \n",
       "0         1  hola hola muy buenas tardes bienvenidos al dia...  \n",
       "1         2  ellos saben que están pasando y se obligan a s...  \n",
       "2         3  de las camas respaldan por lo general faltan d...  \n",
       "3         4  son altas área cama de star wars como creen qu...  \n",
       "4         5  se a manifestarse está claro que nadie quiere ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "registrosAudio =  pd.DataFrame(columns=['folder', 'file','deltaStart', 'deltaEnd','deltaStep','text'])\n",
    "\n",
    "for file in data['file'].unique():\n",
    "    \n",
    "    maskFile =  data['file'] == file\n",
    "    \n",
    "    folder = data.loc[maskFile, 'folder'].unique()\n",
    "    \n",
    "    deltaStart = data.loc[maskFile, 'start'].min()\n",
    "    deltaEnd = deltaStart + td\n",
    "    \n",
    "    endFile = data.loc[maskFile, 'end'].max()\n",
    "    deltaStep=1\n",
    "    while deltaStart <= endFile:\n",
    "        \n",
    "        \n",
    "        maskDelta = (data['start'] >= deltaStart) & (data['end'] < deltaEnd)\n",
    "        \n",
    "        data.loc[maskDelta & maskFile,'deltaStart'] = deltaStart\n",
    "        \n",
    "        data.loc[maskDelta & maskFile,'deltaEnd'] = deltaEnd\n",
    "\n",
    "        text = data.loc[maskDelta & maskFile,'text'].unique()\n",
    "        textDelta = ','.join(text)\n",
    "        newInput=pd.DataFrame([textDelta], columns=['text'])\n",
    "        newInput['file'] = file\n",
    "        newInput['folder'] = folder\n",
    "        newInput['deltaStart'] = deltaStart\n",
    "        newInput['deltaEnd'] = deltaEnd\n",
    "        newInput['deltaStep']=deltaStep\n",
    "        newInput.reset_index(inplace=True,drop=True)\n",
    "        \n",
    "        registrosAudio = registrosAudio.append(newInput)\n",
    "\n",
    "        deltaStart = deltaStart + td\n",
    "        deltaEnd = deltaStart + td\n",
    "        deltaStep=deltaStep+1\n",
    "registrosAudio['file'] = registrosAudio['file'].apply(lambda x: x.split('.')[0]) \n",
    "\n",
    "len_mean = registrosAudio['text'].apply(lambda x: len(x)).mean()\n",
    "\n",
    "mask_filter = registrosAudio['text'].apply(lambda x: len(x)>(len_mean*0.7))\n",
    "\n",
    "\n",
    "registrosAudio=registrosAudio.loc[mask_filter,:]\n",
    "registrosAudio.reset_index(drop=True,inplace=True)\n",
    "print(registrosAudio.shape)\n",
    "registrosAudio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    C5N 8-14 Step 1\n",
       "1    C5N 8-14 Step 2\n",
       "2    C5N 8-14 Step 3\n",
       "3    C5N 8-14 Step 4\n",
       "4    C5N 8-14 Step 5\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux = pd.Series(registrosAudio['file'].apply(lambda x: x.replace(\".wav\",\"\").split(\"-\")[-6:]))\n",
    "aux = aux.apply(lambda x: [int(a) if len(a)<=4 else int(a[-4:]) for a in x])\n",
    "registrosAudio['date'] = aux.apply(lambda x: datetime.datetime(x[0], x[1], x[2], hour=x[3], minute=x[4], second=x[5]))\n",
    "file = registrosAudio['folder'] +\" \"+ registrosAudio['date'].apply(lambda x: str(x.month)+\"-\"+str(x.day))+\" Step \"+registrosAudio['deltaStep'].apply(lambda x: str(x))\n",
    "file.reset_index(inplace=True,drop=True)\n",
    "file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "textos = registrosAudio.loc[:,'text']\n",
    "\n",
    "textos_limpios=[];\n",
    "for t in textos:\n",
    "    t_lower_no_accents=unidecode.unidecode(t.lower()); # sacamos acentos y llevamos a minuscula\n",
    "    t_lower_no_accents_no_punkt=re.sub(r'([^\\s\\w]|_)+','',t_lower_no_accents); # quitamos signos de puntuacion usando una regex que reemplaza todo lo q no sean espacios o palabras por un string vacio\n",
    "    textos_limpios.append(t_lower_no_accents_no_punkt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "### Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stopwords_sp_1: 313\n",
      "stopwords_sp_2: 443\n"
     ]
    }
   ],
   "source": [
    "stopwords_sp_1 = pd.DataFrame(stopwords.words('spanish'),columns=[\"stopwords\"])\n",
    "stopwords_sp_2 = pd.read_csv(\"../Varios/stopwords.txt\",header=None,names=[\"stopwords\"]) #https://countwordsfree.com/stopwords/spanish/txt\n",
    "print(\"stopwords_sp_1:\",stopwords_sp_1.shape[0])\n",
    "print(\"stopwords_sp_2:\",stopwords_sp_2.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_sp_3 = stopwords_sp_2.append(stopwords_sp_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_sp = []\n",
    "for word in stopwords_sp_3.values:\n",
    "    word_clean =  unidecode.unidecode(str(word[0]).lower())\n",
    "    if word_clean not in stopwords_sp:\n",
    "        stopwords_sp.append(word_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjunto final de stopwords: 591\n"
     ]
    }
   ],
   "source": [
    "print(\"Conjunto final de stopwords:\",len(stopwords_sp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "### Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos stemming a las stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemfraseesp_for_stopwords(frase):    \n",
    "    token_words=word_tokenize(frase)\n",
    "    stem_sentence=[]    \n",
    "    spanishStemmer=SnowballStemmer(\"spanish\")\n",
    "    for word in token_words:\n",
    "        stem_sentence.append(spanishStemmer.stem(word))\n",
    "    return \"\".join(stem_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_sp_stemming = []\n",
    "for word in stopwords_sp:\n",
    "    stopword_stem = stemfraseesp_for_stopwords(word)\n",
    "    if stopword_stem not in stopwords_sp_stemming:\n",
    "        stopwords_sp_stemming.append(stopword_stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una tabla que nos permita conservar cuál es la palabra origina de cada stemming para que luego de contar las palabras podamos transformarla en su forma original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_completo = \"\".join(registrosAudio['text'])\n",
    "texto_completo=unidecode.unidecode(texto_completo.lower()); # sacamos acentos y llevamos a minuscula\n",
    "texto_completo=re.sub(r'([^\\s\\w]|_)+','',texto_completo); # quitamos signos de puntuacion usando una regex que reemplaza todo lo q no sean espacios o palabras por un string vacio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_words=word_tokenize(texto_completo)\n",
    "stem_sentence=[]    \n",
    "token_words_clean=[]\n",
    "spanishStemmer=SnowballStemmer(\"spanish\")\n",
    "for word in token_words:\n",
    "    if len(word)>2:\n",
    "        word_stem = spanishStemmer.stem(word)\n",
    "        if word_stem not in stopwords_sp_stemming:\n",
    "            stem_sentence.append(word_stem)\n",
    "            token_words_clean.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem_match = pd.DataFrame([token_words_clean,stem_sentence],index=['original','stem']).T\n",
    "stem_match =  pd.DataFrame(stem_match.groupby('stem')['original'].value_counts())\n",
    "stem_match.columns = ['count']\n",
    "stem_match.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla para matcheo\n",
      "(2924, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stem</th>\n",
       "      <th>original</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cuarenten</td>\n",
       "      <td>cuarentena</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>argentin</td>\n",
       "      <td>argentina</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ciud</td>\n",
       "      <td>ciudad</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>president</td>\n",
       "      <td>presidente</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gobiern</td>\n",
       "      <td>gobierno</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        stem    original  count\n",
       "0  cuarenten  cuarentena    104\n",
       "1   argentin   argentina     74\n",
       "2       ciud      ciudad     71\n",
       "3  president  presidente     69\n",
       "4    gobiern    gobierno     67"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_match = stem_match.sort_values(by='count', ascending=False)\n",
    "stem_match.drop_duplicates(subset=['stem'],keep='first', inplace=True)\n",
    "stem_match.reset_index(drop=True,inplace=True)\n",
    "print(\"Tabla para matcheo\")\n",
    "print(stem_match.shape)\n",
    "stem_match.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos el stemming de los textos que utilizarmos para procesar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemfraseesp(frase):    \n",
    "    token_words=word_tokenize(frase)\n",
    "    stem_sentence=[]    \n",
    "    token_words_clean=[]\n",
    "    spanishStemmer=SnowballStemmer(\"spanish\")\n",
    "    for word in token_words:\n",
    "        if len(word)>2:\n",
    "            word_stem = spanishStemmer.stem(word)\n",
    "            if word_stem not in stopwords_sp_stemming:\n",
    "                stem_sentence.append(word_stem)\n",
    "                stem_sentence.append(\" \")\n",
    "    return \"\".join(stem_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "textos_final = []\n",
    "for t in textos_limpios:\n",
    "    textos_final.append(stemfraseesp(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Textos final con stemming.\n",
      "Ejemplo:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'hol hol tard bienven diari pantall jorn muchisim informacion minut const contact conductor program pabl empez repas titular dia diri lugarten habl definicion president nacion albert fernandez cuarenten analiz fras muchisim president respond sector socied polit med levant ded acus cuarenten sirv element cas impact cas revest pens detall definicion polit detr vei reci clar gobiern enalgun punt empiez reconoc sal call ves activ socied punt establec limitacion gan vid context rig cuestion sanitari h'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Textos final con stemming.\\nEjemplo:\")\n",
    "textos_final[0][0:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------\n",
    "### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=CountVectorizer(stop_words=stopwords_sp,lowercase=True,ngram_range=(1,1), max_df=0.7); #revisar si tenemos que poner stopwords acá, creo que no\n",
    "vectorizer.fit(textos_final);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matcheamos los stemming con su nombre original. Luego usaremos la variable feature_names para nombrar las columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = pd.DataFrame()\n",
    "if len(vectorizer.get_feature_names()[0].split(' '))==2:\n",
    "    aux = pd.Series(vectorizer.get_feature_names())\n",
    "    aux = aux.str.split(' ',expand=True)\n",
    "    aux.columns= ['word1','word2']\n",
    "    aux = aux.merge(stem_match,how='left', left_on='word1',right_on='stem')\n",
    "    aux = aux.merge(stem_match,how='left', left_on='word2',right_on='stem',suffixes=('_1','_2'))\n",
    "    features_names= aux['original_1']+\" \"+aux['original_2']\n",
    "else:\n",
    "    aux = pd.DataFrame(vectorizer.get_feature_names())\n",
    "    aux.columns=['word1']\n",
    "    features_names= aux.merge(stem_match, how='left',left_on='word1',right_on='stem')['original']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "original\n",
       "vacuna             50\n",
       "cobrar             37\n",
       "frontera           32\n",
       "nino               32\n",
       "tomar              29\n",
       "marcha             28\n",
       "cambio             28\n",
       "responsabilidad    27\n",
       "salta              26\n",
       "chicos             26\n",
       "punto              26\n",
       "decia              25\n",
       "familia            25\n",
       "ingreso            25\n",
       "habilitado         24\n",
       "cruzan             24\n",
       "necesita           23\n",
       "escuchar           22\n",
       "jujuy              22\n",
       "deportes           22\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV_encoding=vectorizer.transform(textos_final);\n",
    "pd.DataFrame(CV_encoding.todense(),columns=features_names).sum().sort_values(ascending=False)[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------\n",
    "### Term Frequency Inverse Document Frequency (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>original</th>\n",
       "      <th>aah</th>\n",
       "      <th>abalos</th>\n",
       "      <th>abarca</th>\n",
       "      <th>abasto</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>abdominales</th>\n",
       "      <th>abertis</th>\n",
       "      <th>abierto</th>\n",
       "      <th>abogado</th>\n",
       "      <th>abrazo</th>\n",
       "      <th>...</th>\n",
       "      <th>wilson</th>\n",
       "      <th>yel</th>\n",
       "      <th>yivan</th>\n",
       "      <th>you</th>\n",
       "      <th>ysimple</th>\n",
       "      <th>ytener</th>\n",
       "      <th>yumbo</th>\n",
       "      <th>zelanda</th>\n",
       "      <th>zona</th>\n",
       "      <th>zumo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C5N 8-14 Step 1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017935</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071741</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C5N 8-14 Step 2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034229</td>\n",
       "      <td>0.019297</td>\n",
       "      <td>0.034229</td>\n",
       "      <td>0.029396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034229</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C5N 8-14 Step 3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025538</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C5N 8-14 Step 4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036319</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.03221</td>\n",
       "      <td>0.03221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.072637</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C5N 8-14 Step 5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2826 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "original         aah  abalos  abarca  abasto  abdomen  abdominales   abertis  \\\n",
       "C5N 8-14 Step 1  0.0     0.0     0.0     0.0      0.0          0.0  0.000000   \n",
       "C5N 8-14 Step 2  0.0     0.0     0.0     0.0      0.0          0.0  0.034229   \n",
       "C5N 8-14 Step 3  0.0     0.0     0.0     0.0      0.0          0.0  0.000000   \n",
       "C5N 8-14 Step 4  0.0     0.0     0.0     0.0      0.0          0.0  0.000000   \n",
       "C5N 8-14 Step 5  0.0     0.0     0.0     0.0      0.0          0.0  0.000000   \n",
       "\n",
       "original          abierto   abogado    abrazo  ...  wilson  yel  yivan  \\\n",
       "C5N 8-14 Step 1  0.017935  0.000000  0.000000  ...     0.0  0.0    0.0   \n",
       "C5N 8-14 Step 2  0.019297  0.034229  0.029396  ...     0.0  0.0    0.0   \n",
       "C5N 8-14 Step 3  0.000000  0.000000  0.000000  ...     0.0  0.0    0.0   \n",
       "C5N 8-14 Step 4  0.036319  0.000000  0.055325  ...     0.0  0.0    0.0   \n",
       "C5N 8-14 Step 5  0.000000  0.000000  0.000000  ...     0.0  0.0    0.0   \n",
       "\n",
       "original              you  ysimple   ytener  yumbo  zelanda      zona  zumo  \n",
       "C5N 8-14 Step 1  0.000000  0.00000  0.00000    0.0      0.0  0.071741   0.0  \n",
       "C5N 8-14 Step 2  0.034229  0.00000  0.00000    0.0      0.0  0.000000   0.0  \n",
       "C5N 8-14 Step 3  0.000000  0.00000  0.00000    0.0      0.0  0.025538   0.0  \n",
       "C5N 8-14 Step 4  0.000000  0.03221  0.03221    0.0      0.0  0.072637   0.0  \n",
       "C5N 8-14 Step 5  0.000000  0.00000  0.00000    0.0      0.0  0.000000   0.0  \n",
       "\n",
       "[5 rows x 2826 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tfidf_encoding=TfidfTransformer().fit_transform(CV_encoding);\n",
    "pd.DataFrame(Tfidf_encoding.todense(),columns=features_names,index=file).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------\n",
    "### Tópicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>topico</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C5N 8-14 Step 1</td>\n",
       "      <td>colapsar,terapia,intensiva,pablo,posicion,morir,cambio,definiciones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C5N 8-14 Step 2</td>\n",
       "      <td>convocando,herramienta,fraude,calle,reforma,marcha,proyecto,movilizacion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C5N 8-14 Step 3</td>\n",
       "      <td>nino,avenida,carrera,educacion,comercio,utilizar,palermo,fecoba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C5N 8-14 Step 4</td>\n",
       "      <td>espana,nino,juguete,empieza,verano,ingreso,turistas,juan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C5N 8-14 Step 5</td>\n",
       "      <td>movilizaciones,republica,mental,muerte,tomar,caracter,mensaje,europa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C5N 8-14 Step 6</td>\n",
       "      <td>martin,san,vacuna,macri,marcha,incremento,aceptar,muerte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TN 8-14 Step 1</td>\n",
       "      <td>fuerzas,cobrar,frontera,salta,bolivia,ratito,detenidos,cruzan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TN 8-14 Step 2</td>\n",
       "      <td>cobrar,beneficios,funcionarios,frontera,jujuy,salta,fase,respiradores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TN 8-14 Step 3</td>\n",
       "      <td>vacuna,escuela,voto,concejales,chicos,cobrar,necesita,clases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TN 8-14 Step 4</td>\n",
       "      <td>discurso,sergio,fernando,exito,contradiccion,responsabilidad,decreto,confuso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TN 8-14 Step 5</td>\n",
       "      <td>casinos,paula,entrenamiento,olimpicos,escuela,juegos,chubut,nino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TN 8-14 Step 6</td>\n",
       "      <td>barcelona,seleccionadas,jujuy,equipo,doce,panza,gol,morales</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               file  \\\n",
       "0   C5N 8-14 Step 1   \n",
       "1   C5N 8-14 Step 2   \n",
       "2   C5N 8-14 Step 3   \n",
       "3   C5N 8-14 Step 4   \n",
       "4   C5N 8-14 Step 5   \n",
       "5   C5N 8-14 Step 6   \n",
       "6    TN 8-14 Step 1   \n",
       "7    TN 8-14 Step 2   \n",
       "8    TN 8-14 Step 3   \n",
       "9    TN 8-14 Step 4   \n",
       "10   TN 8-14 Step 5   \n",
       "11   TN 8-14 Step 6   \n",
       "\n",
       "                                                                          topico  \n",
       "0            colapsar,terapia,intensiva,pablo,posicion,morir,cambio,definiciones  \n",
       "1       convocando,herramienta,fraude,calle,reforma,marcha,proyecto,movilizacion  \n",
       "2                nino,avenida,carrera,educacion,comercio,utilizar,palermo,fecoba  \n",
       "3                       espana,nino,juguete,empieza,verano,ingreso,turistas,juan  \n",
       "4           movilizaciones,republica,mental,muerte,tomar,caracter,mensaje,europa  \n",
       "5                       martin,san,vacuna,macri,marcha,incremento,aceptar,muerte  \n",
       "6                  fuerzas,cobrar,frontera,salta,bolivia,ratito,detenidos,cruzan  \n",
       "7          cobrar,beneficios,funcionarios,frontera,jujuy,salta,fase,respiradores  \n",
       "8                   vacuna,escuela,voto,concejales,chicos,cobrar,necesita,clases  \n",
       "9   discurso,sergio,fernando,exito,contradiccion,responsabilidad,decreto,confuso  \n",
       "10              casinos,paula,entrenamiento,olimpicos,escuela,juegos,chubut,nino  \n",
       "11                   barcelona,seleccionadas,jujuy,equipo,doce,panza,gol,morales  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = pd.DataFrame(Tfidf_encoding.todense(),columns=features_names)\n",
    "tfidf.index = file\n",
    "tfidf= tfidf.T\n",
    "\n",
    "topicos = []\n",
    "for x in tfidf.columns:\n",
    "    topico_x = ','.join(tfidf[x].sort_values(ascending=False)[0:8].index)\n",
    "    topicos.append([x,topico_x])\n",
    "\n",
    "topicos = pd.DataFrame(topicos,columns=['file','topico'])\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "topicos #Esto se puede usar para la nube, pero no prepondera palabras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "## Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras negativas\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palabra</th>\n",
       "      <th>puntuacion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>coño</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1894</th>\n",
       "      <td>perras</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1757</th>\n",
       "      <td>Niggas</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1893</th>\n",
       "      <td>perra</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2346</th>\n",
       "      <td>tragona</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      palabra  puntuacion\n",
       "584      coño          -5\n",
       "1894   perras          -5\n",
       "1757   Niggas          -5\n",
       "1893    perra          -5\n",
       "2346  tragona          -5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras positivas\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palabra</th>\n",
       "      <th>puntuacion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1326</th>\n",
       "      <td>Hurra</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>encantados</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>asombroso</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>excepcional</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608</th>\n",
       "      <td>magnífico</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          palabra  puntuacion\n",
       "1326        Hurra           5\n",
       "910    encantados           5\n",
       "283     asombroso           5\n",
       "1072  excepcional           5\n",
       "1608    magnífico           5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras con poca tendencia\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palabra</th>\n",
       "      <th>puntuacion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>adoptar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2421</th>\n",
       "      <td>veredictos</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>anti</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>evitar</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>asustadizo</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         palabra  puntuacion\n",
       "68       adoptar           1\n",
       "2421  veredictos          -1\n",
       "206         anti          -1\n",
       "1058      evitar          -1\n",
       "291   asustadizo          -1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "afinn = pd.read_csv(\"../Varios/lexico_afinn_es.csv\",encoding='latin-1')\n",
    "afinn.dropna(inplace=True)\n",
    "afinn=afinn[['palabra','puntuacion']]\n",
    "print(\"Palabras negativas\")\n",
    "display(afinn.sort_values(by='puntuacion').head(5))\n",
    "\n",
    "print(\"Palabras positivas\")\n",
    "display(afinn.sort_values(by='puntuacion',ascending=False).head(5))\n",
    "\n",
    "print(\"Palabras con poca tendencia\")\n",
    "afinn.loc[afinn['puntuacion'].between(-1,1),:].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>palabra</th>\n",
       "      <th>puntuacion</th>\n",
       "      <th>stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a bordo</td>\n",
       "      <td>1</td>\n",
       "      <td>abord</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abandona</td>\n",
       "      <td>-2</td>\n",
       "      <td>abandon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abatido</td>\n",
       "      <td>-2</td>\n",
       "      <td>abat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>aborrece</td>\n",
       "      <td>-3</td>\n",
       "      <td>aborrec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>adoptar</td>\n",
       "      <td>1</td>\n",
       "      <td>adopt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     palabra  puntuacion     stem\n",
       "0    a bordo           1    abord\n",
       "1   abandona          -2  abandon\n",
       "4    abatido          -2     abat\n",
       "6   aborrece          -3  aborrec\n",
       "10   adoptar           1    adopt"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "afinn_stem = []\n",
    "for word in afinn['palabra']:\n",
    "    afinn_stem.append(stemfraseesp_for_stopwords(word))\n",
    "\n",
    "afinn_stem = afinn.join(pd.DataFrame(afinn_stem))\n",
    "afinn_stem.columns = ['palabra','puntuacion','stem']\n",
    "afinn_stem.drop_duplicates(subset='stem',inplace=True)\n",
    "afinn_stem.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_stemCount = pd.DataFrame(CV_encoding.todense(),columns=vectorizer.get_feature_names(),index=file).T\n",
    "file_stemCount.reset_index(inplace=True)\n",
    "file_stemCount.rename(columns={'index':'word'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C5N 8-14 Step 1</td>\n",
       "      <td>-58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C5N 8-14 Step 2</td>\n",
       "      <td>-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C5N 8-14 Step 3</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C5N 8-14 Step 4</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C5N 8-14 Step 5</td>\n",
       "      <td>-52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              file  sentiment\n",
       "0  C5N 8-14 Step 1        -58\n",
       "1  C5N 8-14 Step 2         -8\n",
       "2  C5N 8-14 Step 3         33\n",
       "3  C5N 8-14 Step 4         12\n",
       "4  C5N 8-14 Step 5        -52"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_analysis = file_stemCount.merge(afinn_stem,left_on='word',right_on='stem')\n",
    "sentiment_analysis\n",
    "\n",
    "for column in file.values:\n",
    "    sentiment_analysis[column] = sentiment_analysis[column]*sentiment_analysis['puntuacion']\n",
    "\n",
    "sentiment_analysis_final = sentiment_analysis[list(file.values)].sum().T\n",
    "sentiment_analysis_final=pd.DataFrame(sentiment_analysis_final,columns=['sentiment'])\n",
    "sentiment_analysis_final.reset_index(inplace=True)\n",
    "sentiment_analysis_final.rename(columns={'index':'file'}, inplace=True)\n",
    "sentiment_analysis_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>topico</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C5N 8-14 Step 1</td>\n",
       "      <td>colapsar,terapia,intensiva,pablo,posicion,morir,cambio,definiciones</td>\n",
       "      <td>-58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C5N 8-14 Step 2</td>\n",
       "      <td>convocando,herramienta,fraude,calle,reforma,marcha,proyecto,movilizacion</td>\n",
       "      <td>-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C5N 8-14 Step 3</td>\n",
       "      <td>nino,avenida,carrera,educacion,comercio,utilizar,palermo,fecoba</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C5N 8-14 Step 4</td>\n",
       "      <td>espana,nino,juguete,empieza,verano,ingreso,turistas,juan</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C5N 8-14 Step 5</td>\n",
       "      <td>movilizaciones,republica,mental,muerte,tomar,caracter,mensaje,europa</td>\n",
       "      <td>-52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C5N 8-14 Step 6</td>\n",
       "      <td>martin,san,vacuna,macri,marcha,incremento,aceptar,muerte</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TN 8-14 Step 1</td>\n",
       "      <td>fuerzas,cobrar,frontera,salta,bolivia,ratito,detenidos,cruzan</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TN 8-14 Step 2</td>\n",
       "      <td>cobrar,beneficios,funcionarios,frontera,jujuy,salta,fase,respiradores</td>\n",
       "      <td>-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TN 8-14 Step 3</td>\n",
       "      <td>vacuna,escuela,voto,concejales,chicos,cobrar,necesita,clases</td>\n",
       "      <td>-6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TN 8-14 Step 4</td>\n",
       "      <td>discurso,sergio,fernando,exito,contradiccion,responsabilidad,decreto,confuso</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TN 8-14 Step 5</td>\n",
       "      <td>casinos,paula,entrenamiento,olimpicos,escuela,juegos,chubut,nino</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TN 8-14 Step 6</td>\n",
       "      <td>barcelona,seleccionadas,jujuy,equipo,doce,panza,gol,morales</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               file  \\\n",
       "0   C5N 8-14 Step 1   \n",
       "1   C5N 8-14 Step 2   \n",
       "2   C5N 8-14 Step 3   \n",
       "3   C5N 8-14 Step 4   \n",
       "4   C5N 8-14 Step 5   \n",
       "5   C5N 8-14 Step 6   \n",
       "6    TN 8-14 Step 1   \n",
       "7    TN 8-14 Step 2   \n",
       "8    TN 8-14 Step 3   \n",
       "9    TN 8-14 Step 4   \n",
       "10   TN 8-14 Step 5   \n",
       "11   TN 8-14 Step 6   \n",
       "\n",
       "                                                                          topico  \\\n",
       "0            colapsar,terapia,intensiva,pablo,posicion,morir,cambio,definiciones   \n",
       "1       convocando,herramienta,fraude,calle,reforma,marcha,proyecto,movilizacion   \n",
       "2                nino,avenida,carrera,educacion,comercio,utilizar,palermo,fecoba   \n",
       "3                       espana,nino,juguete,empieza,verano,ingreso,turistas,juan   \n",
       "4           movilizaciones,republica,mental,muerte,tomar,caracter,mensaje,europa   \n",
       "5                       martin,san,vacuna,macri,marcha,incremento,aceptar,muerte   \n",
       "6                  fuerzas,cobrar,frontera,salta,bolivia,ratito,detenidos,cruzan   \n",
       "7          cobrar,beneficios,funcionarios,frontera,jujuy,salta,fase,respiradores   \n",
       "8                   vacuna,escuela,voto,concejales,chicos,cobrar,necesita,clases   \n",
       "9   discurso,sergio,fernando,exito,contradiccion,responsabilidad,decreto,confuso   \n",
       "10              casinos,paula,entrenamiento,olimpicos,escuela,juegos,chubut,nino   \n",
       "11                   barcelona,seleccionadas,jujuy,equipo,doce,panza,gol,morales   \n",
       "\n",
       "    sentiment  \n",
       "0         -58  \n",
       "1          -8  \n",
       "2          33  \n",
       "3          12  \n",
       "4         -52  \n",
       "5          46  \n",
       "6          -5  \n",
       "7         -25  \n",
       "8          -6  \n",
       "9           2  \n",
       "10         23  \n",
       "11          8  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = topicos.merge(sentiment_analysis_final,on='file')\n",
    "final[0:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['canal'] = final['file'].apply(lambda x: x.split(' ')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "canal\n",
       "C5N   -4.5\n",
       "TN    -0.5\n",
       "Name: sentiment, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.groupby(['canal'])['sentiment'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canal\n",
      "C5N    1\n",
      "TN     1\n",
      "Name: macri, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "canal\n",
       "C5N    46\n",
       "TN     -6\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final['macri'] = final['topico'].apply(lambda x: 1 if 'vacuna' in x else 0)\n",
    "\n",
    "\n",
    "mask = final['macri'] == 1\n",
    "final_macri = final.loc[mask,:]\n",
    "\n",
    "print(final_macri.groupby(['canal'])['macri'].sum())\n",
    "final_macri.groupby(['canal'])['sentiment'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "auxiliar= []\n",
    "for x in final['topico']:\n",
    "    asd = x.replace(',',' ')\n",
    "    auxiliar.append(asd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_topico=[]\n",
    "\n",
    "for topico_x in auxiliar:\n",
    "    asd = word_tokenize(topico_x)\n",
    "    for x in asd:\n",
    "        word_topico.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nino         3\n",
       "cobrar       3\n",
       "salta        2\n",
       "marcha       2\n",
       "muerte       2\n",
       "frontera     2\n",
       "escuela      2\n",
       "jujuy        2\n",
       "vacuna       2\n",
       "sergio       1\n",
       "juegos       1\n",
       "proyecto     1\n",
       "caracter     1\n",
       "morales      1\n",
       "detenidos    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(word_topico).value_counts(ascending=False)[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
