{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clase ProcesarVideo\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "#import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "from PIL import Image\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProcesarVideo:\n",
    "    def __init__(self, basePath='.', videoFileName=None, fyh=None, fuente=None):\n",
    "        self.basePath = basePath\n",
    "        self.fileName = basePath + '/canales/' + fuente + '/' + videoFileName\n",
    "        self.path_ddbb = basePath + '/ddbb'\n",
    "        self.path_indentificadas = basePath + '/img/indentificadas'\n",
    "        self.path_no_indentificadas = basePath + '/img/no_indentificadas'\n",
    "        #self.fechaYhora = datetime.strptime(fyh, '%d/%m/%Y %H:%M:%S')\n",
    "        self.fechaYhora = datetime.strptime(fyh, '%Y-%m-%d-%H-%M-%S')\n",
    "        self.fuente=fuente\n",
    "        self.mostrarVideo = False\n",
    "        self.generoPorPersonaje={}\n",
    "        self.videoFileName = videoFileName\n",
    "        \n",
    "    def __inicializar(self):\n",
    "        self.genderProto = self.basePath + '/model/gender_deploy.prototxt'\n",
    "        self.genderModel = self.basePath + '/model/gender_net.caffemodel'\n",
    "        self.genderNet = cv2.dnn.readNet(self.genderProto, self.genderModel)\n",
    "        self.genderList = ['M', 'F']\n",
    "        self.MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\n",
    "        \n",
    "#         print('   basePath', self.basePath)\n",
    "#         print('   videoFileName', self.fileName)\n",
    "#         print('   path_ddbb', self.path_ddbb)\n",
    "#         print('   path_indentificadas', self.path_indentificadas)\n",
    "#         print('   path_no_indentificadas', self.path_no_indentificadas)\n",
    "#         print('   genderProto', self.genderProto)\n",
    "#         print('   genderModel', self.genderModel)\n",
    "\n",
    "    def __convertToRGB(self, image):\n",
    "        return cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    def __saveImage(self, path, fechaYhora, sz, image):\n",
    "        pil_image = Image.fromarray(image)\n",
    "        file = path +'/'+ fechaYhora + '_'+ sz +'.png'\n",
    "        pil_image.save(file)\n",
    "\n",
    "    def __cargarBaseDeDatos(self):\n",
    "        faces = os.listdir(self.path_ddbb)\n",
    "\n",
    "        self.encodings = []\n",
    "        self.nombres = []\n",
    "        \n",
    "        for face in faces:\n",
    "            fileName = self.path_ddbb +'/'+ face\n",
    "            image = face_recognition.load_image_file(fileName)\n",
    "            encoding = face_recognition.face_encodings(image)[0]\n",
    "            nombre = os.path.splitext(face)[0]\n",
    "            \n",
    "            self.encodings.append(encoding)\n",
    "            self.nombres.append(nombre)\n",
    "            \n",
    "            #Obtiene el genero de los personajes de la base de datos\n",
    "            blob = cv2.dnn.blobFromImage(image, 1.0, (227, 227), self.MODEL_MEAN_VALUES, swapRB=False)\n",
    "            self.genderNet.setInput(blob)\n",
    "            genderPreds = self.genderNet.forward()\n",
    "            genero = self.genderList[genderPreds[0].argmax()]\n",
    "            self.generoPorPersonaje[nombre] = genero        \n",
    "            #print('   ', nombre, genero)           \n",
    "        print('  personajes', len(self.nombres))\n",
    "        \n",
    "    def __detectarGenero(self, nombre, image):\n",
    "        genero = None\n",
    "        if nombre is None:\n",
    "            blob = cv2.dnn.blobFromImage(image, 1.0, (227, 227), self.MODEL_MEAN_VALUES, swapRB=False)\n",
    "            self.genderNet.setInput(blob)\n",
    "            genderPreds = self.genderNet.forward()\n",
    "            genero = self.genderList[genderPreds[0].argmax()]\n",
    "        else:  \n",
    "            genero = self.generoPorPersonaje.get(nombre)\n",
    "        return(genero)\n",
    "            \n",
    "    def __faceRecognition(self, image, fechaYhora):\n",
    "        personaje = self.diccionario['personaje']\n",
    "        fecha_hora = self.diccionario['fecha_hora']\n",
    "        genero = self.diccionario['genero']\n",
    "\n",
    "        faceLocations = face_recognition.face_locations(image)\n",
    "\n",
    "        if len(faceLocations) > 0:\n",
    "            for faceLocation in faceLocations:\n",
    "\n",
    "                top, right, bottom, left = faceLocation\n",
    "\n",
    "                #Marco ampliado\n",
    "                marginW = int((right - left) * 0.25)\n",
    "                marginT = int((bottom - top) * 0.5)\n",
    "                marginB = int((bottom - top) * 0.25)\n",
    "\n",
    "                faceImage = image[top-marginT:bottom+marginB, left-marginW:right+marginW]\n",
    "\n",
    "                fecha_hora.append(fechaYhora)\n",
    "\n",
    "                indiceNoEncontrado = 0\n",
    "\n",
    "                if(len(self.encodings) > 0):\n",
    "                    \n",
    "                    fe = face_recognition.face_encodings(faceImage)\n",
    "                    if len(fe) > 0:\n",
    "                        faceEncode = fe[0]\n",
    "\n",
    "                        matches = face_recognition.compare_faces(self.encodings, faceEncode)\n",
    "\n",
    "                        face_distances = face_recognition.face_distance(self.encodings, faceEncode)\n",
    "                        best_match_index = np.argmin(face_distances)\n",
    "\n",
    "                        if matches[best_match_index]:\n",
    "                            name = self.nombres[best_match_index]\n",
    "                            personaje.append(name)\n",
    "                            genero.append(self.__detectarGenero(name, faceImage))\n",
    "                            #self.__saveImage(self.path_indentificadas, fechaYhora.strftime(\"%Y%d%m_%H%M%S\"), name, self.__convertToRGB(faceImage))\n",
    "                        else:\n",
    "                            personaje.append('NO IDENTIFICADO')\n",
    "                            self.__saveImage(self.path_no_indentificadas, fechaYhora.strftime(\"%Y%d%m_%H%M%S\"), str(indiceNoEncontrado), self.__convertToRGB(faceImage))\n",
    "                            indiceNoEncontrado += 1\n",
    "                            genero.append(self.__detectarGenero(None, faceImage))\n",
    "                    else:\n",
    "                        personaje.append('SIN PERSONAS IDENTIFICABLES')\n",
    "                        genero.append(None)\n",
    "                else:\n",
    "                    personaje.append('NO IDENTIFICADO')\n",
    "                    self.__saveImage(self.path_no_indentificadas, fechaYhora.strftime(\"%Y%d%m_%H%M%S\"), str(indiceNoEncontrado), self.__convertToRGB(faceImage))\n",
    "                    indiceNoEncontrado += 1\n",
    "                    genero.append(self.__detectarGenero('NO IDENTIFICADO', faceImage))\n",
    "        else:\n",
    "            fecha_hora.append(fechaYhora)\n",
    "            personaje.append('SIN PERSONAS IDENTIFICABLES')\n",
    "            genero.append(None)\n",
    "\n",
    "        print(f'   {fechaYhora} personas {len(faceLocations)}\\r', end=\"\")\n",
    "\n",
    "        return(faceLocations)\n",
    "    \n",
    "    def __enmarcarCaras(self, frame, faceLocations):\n",
    "        thickness = 2\n",
    "        for faceLocation in faceLocations:\n",
    "\n",
    "            top, right, bottom, left = faceLocation\n",
    "\n",
    "            #Marco ampliado\n",
    "            marginW = int((right - left) * 0.25)\n",
    "            marginT = int((bottom - top) * 0.5)\n",
    "            marginB = int((bottom - top) * 0.25)\n",
    "\n",
    "            start_point = (left-marginW, top-marginT)\n",
    "            end_point = (right+marginW, bottom+marginB)\n",
    "            color = (0, 255, 0) \n",
    "\n",
    "            frame = cv2.rectangle(frame, start_point, end_point, color, thickness)\n",
    "\n",
    "            #Cara  \n",
    "            start_point = (left, top)\n",
    "            end_point = (right, bottom)\n",
    "            color = (255, 0, 0) \n",
    "\n",
    "            frame = cv2.rectangle(frame, start_point, end_point, color, thickness)\n",
    "            \n",
    "    def __crearDirectorios(self):\n",
    "\n",
    "        if(not os.path.exists(self.basePath + '/img')):\n",
    "            os.mkdir(self.basePath + '/img')\n",
    "\n",
    "        if(not os.path.exists(self.path_indentificadas)):\n",
    "            os.mkdir(self.path_indentificadas)\n",
    "\n",
    "        if(not os.path.exists(self.path_no_indentificadas)):\n",
    "            os.mkdir(self.path_no_indentificadas)\n",
    "            \n",
    "        if(not os.path.exists(self.path_ddbb)):\n",
    "            os.mkdir(self.path_ddbb)\n",
    "\n",
    "    def __procesar(self):\n",
    "        agrupamiento = 0\n",
    "\n",
    "        self.diccionario = {}\n",
    "        self.diccionario['personaje'] = []\n",
    "        self.diccionario['fecha_hora'] = []\n",
    "        self.diccionario['genero'] = []\n",
    "\n",
    "        videoFile = self.fileName\n",
    "        print('  videoFile',videoFile)\n",
    "        \n",
    "        cap = cv2.VideoCapture(videoFile)\n",
    "        \n",
    "        \n",
    "        \n",
    "        try:           \n",
    "            while cap.isOpened():\n",
    "                \n",
    "                ret, frame = cap.read()\n",
    "\n",
    "                #Toma un frame por cada segundo\n",
    "                if ret == True:\n",
    "                    faceLocations = self.__faceRecognition(frame, self.fechaYhora)\n",
    "\n",
    "                    if(self.mostrarVideo):\n",
    "                        self.__enmarcarCaras(frame, faceLocations)\n",
    "                        cv2.imshow('Frame', frame)\n",
    "\n",
    "                    agrupamiento += 1\n",
    "                    self.fechaYhora += timedelta(seconds=1)\n",
    "\n",
    "                    #Q = terminar si se esta mostrando el video\n",
    "                    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                        break\n",
    "                else:\n",
    "                    break\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(\"Error\", e.args)\n",
    "            \n",
    "        finally:\n",
    "            cap.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            \n",
    "    def __crearDF(self):\n",
    "        df = pd.DataFrame()\n",
    "        df['personaje'] = pd.Series(self.diccionario['personaje'])\n",
    "        df['fecha_hora'] = pd.Series(self.diccionario['fecha_hora'])\n",
    "        df['genero'] = pd.Series(self.diccionario['genero'])\n",
    "        df['file'] = self.fuente + self.videoFileName\n",
    "        \n",
    "        if self.fuente is not None:\n",
    "            df['fuente'] = self.fuente\n",
    "            \n",
    "        return(df)\n",
    "        \n",
    "    def transform(self):\n",
    "        print('inicializar')\n",
    "        self.__inicializar()\n",
    "\n",
    "        print('verificando directorios')\n",
    "        self.__crearDirectorios()\n",
    "        \n",
    "        print('cargando base de datos')\n",
    "        self.__cargarBaseDeDatos()\n",
    "        \n",
    "        print('procesando')\n",
    "        self.__procesar()\n",
    "        \n",
    "        print('creando DataFrame')\n",
    "        df = self.__crearDF()\n",
    "        return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proceso\n",
    "---\n",
    "El proceso toma los videos de directorio <b>../Data/Video/canales</b> agrupados por fuente Ej:\n",
    "\n",
    "<pre>\n",
    "canales\n",
    "    TN\n",
    "        2020-08-06-22-00-00.mp4\n",
    "        2020-09-06-22-00-00.mp4\n",
    "    C5N\n",
    "</pre>\n",
    "\n",
    "El nombre del archivo debe contener la fecha y hora de captura con el siguiente formato Ej:<br>\n",
    "<b>yyyy-mm-dd-hh-mi-ss.mp4</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalar\n",
    "`pip install face-recognition`<br>\n",
    "`pip install opencv-python`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejecutar en Python version <b>3.8.3</b>\n",
    "`!python --version`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fuente: C5N fyh: 2020-08-14-17-55-49 video: 2020-08-14-17-55-49.mp4\n",
      "inicializar\n",
      "verificando directorios\n",
      "cargando base de datos\n",
      "  personajes 43\n",
      "procesando\n",
      "  videoFile ../Data/Video/canales/C5N/2020-08-14-17-55-49.mp4\n",
      "creando DataFrame00:46 personas 0\n",
      "fuente: TN fyh: 2020-08-14-18-59-25 video: 2020-08-14-18-59-25.mp4\n",
      "inicializar\n",
      "verificando directorios\n",
      "cargando base de datos\n",
      "  personajes 43\n",
      "procesando\n",
      "  videoFile ../Data/Video/canales/TN/2020-08-14-18-59-25.mp4\n",
      "creando DataFrame02:30 personas 1\n"
     ]
    }
   ],
   "source": [
    "base = \"../Data/Video\"\n",
    "savePath = '..Data/Video/TablasVideo'\n",
    "dir_videos = base + \"/canales\"\n",
    "dataFrames = []\n",
    "\n",
    "folders_video = listdir(dir_videos)\n",
    "for fuente in folders_video:\n",
    "    if not fuente.startswith(\".\"):\n",
    "        videos = listdir(dir_videos + '/'+ fuente)\n",
    "        for video in videos:\n",
    "            if not video.startswith(\".\"):\n",
    "                fyh = os.path.splitext(video)[0]\n",
    "\n",
    "                print('fuente:', fuente, 'fyh:', fyh, 'video:', video)\n",
    "                pv = ProcesarVideo(basePath=base, videoFileName=video, fyh=fyh, fuente=fuente)\n",
    "                #pv.mostrarVideo=True\n",
    "                df = pv.transform()\n",
    "                df.to_csv(base + '/' + fuente + video +'.csv')\n",
    "                dataFrames.append(df)\n",
    "\n",
    "                #Graficar resultados\n",
    "                prob = df.personaje.value_counts()\n",
    "                #prob.plot(kind='bar', figsize=(12,6))\n",
    "                #plt.xticks(rotation=90)\n",
    "                #plt.ylabel('segundos')\n",
    "                #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
