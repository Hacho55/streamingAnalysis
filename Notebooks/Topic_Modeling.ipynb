{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import unidecode\n",
    "import re\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.patches as mpatches\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder</th>\n",
       "      <th>path_audio</th>\n",
       "      <th>file</th>\n",
       "      <th>date</th>\n",
       "      <th>text_complete</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C5N</td>\n",
       "      <td>../Data/Audio/C5N/C5N2020-08-11-17-59-23.wav</td>\n",
       "      <td>C5N2020-08-11-17-59-23.wav</td>\n",
       "      <td>2020-08-11 17:59:23</td>\n",
       "      <td>el doctor adolfo ruiz stein que había dicho qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C5N</td>\n",
       "      <td>../Data/Audio/C5N/C5N2020-08-14-17-55-49.wav</td>\n",
       "      <td>C5N2020-08-14-17-55-49.wav</td>\n",
       "      <td>2020-08-14 17:55:49</td>\n",
       "      <td>a hola hola muy buenas tardes bienvenidos al d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TN</td>\n",
       "      <td>../Data/Audio/TN/TN2020-08-11-19-01-34.wav</td>\n",
       "      <td>TN2020-08-11-19-01-34.wav</td>\n",
       "      <td>2020-08-11 19:01:34</td>\n",
       "      <td>de ciento cincuenta mil casos corresponder al ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TN</td>\n",
       "      <td>../Data/Audio/TN/TN2020-08-14-18-59-25.wav</td>\n",
       "      <td>TN2020-08-14-18-59-25.wav</td>\n",
       "      <td>2020-08-14 18:59:25</td>\n",
       "      <td>de los colores que se habían ido arrojó de las...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  folder                                    path_audio  \\\n",
       "0    C5N  ../Data/Audio/C5N/C5N2020-08-11-17-59-23.wav   \n",
       "1    C5N  ../Data/Audio/C5N/C5N2020-08-14-17-55-49.wav   \n",
       "2     TN    ../Data/Audio/TN/TN2020-08-11-19-01-34.wav   \n",
       "3     TN    ../Data/Audio/TN/TN2020-08-14-18-59-25.wav   \n",
       "\n",
       "                         file                 date  \\\n",
       "0  C5N2020-08-11-17-59-23.wav  2020-08-11 17:59:23   \n",
       "1  C5N2020-08-14-17-55-49.wav  2020-08-14 17:55:49   \n",
       "2   TN2020-08-11-19-01-34.wav  2020-08-11 19:01:34   \n",
       "3   TN2020-08-14-18-59-25.wav  2020-08-14 18:59:25   \n",
       "\n",
       "                                       text_complete  \n",
       "0  el doctor adolfo ruiz stein que había dicho qu...  \n",
       "1  a hola hola muy buenas tardes bienvenidos al d...  \n",
       "2  de ciento cincuenta mil casos corresponder al ...  \n",
       "3  de los colores que se habían ido arrojó de las...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../Data procesada/data_audio_concatenada.csv\")\n",
    "data.drop(columns=['Unnamed: 0'],inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = pd.Series(data['file'].apply(lambda x: x.replace(\".wav\",\"\").split(\"-\")[-6:]))\n",
    "aux = aux.apply(lambda x: [int(a) if len(a)<=4 else int(a[-4:]) for a in x])\n",
    "data['date'] = aux.apply(lambda x: datetime.datetime(x[0], x[1], x[2], hour=x[3], minute=x[4], second=x[5]))\n",
    "file = data['folder'] +\"-\"+ data['date'].apply(lambda x: str(x.month)+\"-\"+str(x.day))\n",
    "data['day'] = data['date'].apply(lambda x: str(x.day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data=data.loc[data['day']==\"14\",:]\n",
    "# data.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "textos = data.loc[:,'text_complete']\n",
    "\n",
    "textos_limpios=[];\n",
    "for t in textos:\n",
    "    t_lower_no_accents=unidecode.unidecode(t.lower()); # sacamos acentos y llevamos a minuscula\n",
    "    t_lower_no_accents_no_punkt=re.sub(r'([^\\s\\w]|_)+','',t_lower_no_accents); # quitamos signos de puntuacion usando una regex que reemplaza todo lo q no sean espacios o palabras por un string vacio\n",
    "    textos_limpios.append(t_lower_no_accents_no_punkt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defimimos una función que aplica stemming a una frase en castellano:\n",
    "def stemfraseesp(frase):    \n",
    "    token_words=word_tokenize(frase)\n",
    "    token_words\n",
    "    stem_sentence=[]    \n",
    "    spanishStemmer=SnowballStemmer(\"spanish\",ignore_stopwords=True)\n",
    "    for word in token_words:\n",
    "        stem_sentence.append(spanishStemmer.stem(word))\n",
    "        stem_sentence.append(\" \")\n",
    "    return \"\".join(stem_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_sp = stopwords.words('spanish');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_completo = \"\".join(data['text_complete'])\n",
    "texto_completo=unidecode.unidecode(texto_completo.lower()); # sacamos acentos y llevamos a minuscula\n",
    "texto_completo=re.sub(r'([^\\s\\w]|_)+','',texto_completo); # quitamos signos de puntuacion usando una regex que reemplaza todo lo q no sean espacios o palabras por un string vacio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_words=word_tokenize(texto_completo)\n",
    "token_words = [i for i in token_words if i not in stopwords_sp]\n",
    "stem_sentence=[]\n",
    "spanishStemmer=SnowballStemmer(\"spanish\",ignore_stopwords=True)\n",
    "for word in token_words:\n",
    "    stem_sentence.append(spanishStemmer.stem(word))\n",
    "    stem_sentence.append(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem_sentence = pd.Series(stem_sentence)\n",
    "mask = stem_sentence != \" \"\n",
    "stem_sentence= stem_sentence.loc[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem_match = pd.DataFrame([token_words,stem_sentence]).T\n",
    "stem_match.columns = ['original','stem']\n",
    "stem_match = stem_match.groupby('stem')['original'].value_counts()\n",
    "stem_match = pd.DataFrame(stem_match)\n",
    "stem_match.columns = ['Count']\n",
    "stem_match.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4476, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stem</th>\n",
       "      <th>original</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mas</td>\n",
       "      <td>mas</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>si</td>\n",
       "      <td>si</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tambi</td>\n",
       "      <td>tambien</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ahor</td>\n",
       "      <td>ahora</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>buen</td>\n",
       "      <td>bueno</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cuarenten</td>\n",
       "      <td>cuarentena</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>estan</td>\n",
       "      <td>estan</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gobiern</td>\n",
       "      <td>gobierno</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>argentin</td>\n",
       "      <td>argentina</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hoy</td>\n",
       "      <td>hoy</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>hac</td>\n",
       "      <td>hace</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gent</td>\n",
       "      <td>gente</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>va</td>\n",
       "      <td>va</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dia</td>\n",
       "      <td>dia</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>president</td>\n",
       "      <td>presidente</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>vam</td>\n",
       "      <td>vamos</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>pued</td>\n",
       "      <td>puede</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ver</td>\n",
       "      <td>ver</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ciud</td>\n",
       "      <td>ciudad</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ser</td>\n",
       "      <td>ser</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         stem    original  Count\n",
       "0         mas         mas    310\n",
       "1          si          si    288\n",
       "2       tambi     tambien    245\n",
       "3        ahor       ahora    167\n",
       "4        buen       bueno    166\n",
       "5   cuarenten  cuarentena    137\n",
       "6       estan       estan    129\n",
       "7     gobiern    gobierno    119\n",
       "8    argentin   argentina    117\n",
       "9         hoy         hoy    113\n",
       "10        hac        hace    110\n",
       "11       gent       gente    108\n",
       "12         va          va    108\n",
       "13        dia         dia    108\n",
       "14  president  presidente    105\n",
       "15        vam       vamos    104\n",
       "16       pued       puede    103\n",
       "17        ver         ver    100\n",
       "18       ciud      ciudad     97\n",
       "19        ser         ser     94"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_match = stem_match.sort_values(by='Count', ascending=False)\n",
    "stem_match.drop_duplicates(subset=['stem'],keep='first', inplace=True)\n",
    "stem_match.reset_index(drop=True,inplace=True)\n",
    "print(stem_match.shape)\n",
    "stem_match.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "backup=textos_limpios\n",
    "auxiliar = []\n",
    "for t in textos_limpios:\n",
    "    auxiliar.append(stemfraseesp(t))\n",
    "    \n",
    "textos_limpios=auxiliar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>original</th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aahora</th>\n",
       "      <th>abajo</th>\n",
       "      <th>abasto</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>abdominales</th>\n",
       "      <th>abertis</th>\n",
       "      <th>abierto</th>\n",
       "      <th>abismo</th>\n",
       "      <th>...</th>\n",
       "      <th>ymuy</th>\n",
       "      <th>you</th>\n",
       "      <th>youtube</th>\n",
       "      <th>ypor</th>\n",
       "      <th>yreino</th>\n",
       "      <th>yumbo</th>\n",
       "      <th>zaragoza</th>\n",
       "      <th>zelanda</th>\n",
       "      <th>zona</th>\n",
       "      <th>zonda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 4461 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "original  aa  aaa  aahora  abajo  abasto  abdomen  abdominales  abertis  \\\n",
       "0          1    0       0      4       0        0            0        0   \n",
       "1          1    0       0      0       0        0            0        1   \n",
       "2          1    1       0      0       0        0            0        0   \n",
       "3          2    0       1      1       2        1            2        0   \n",
       "\n",
       "original  abierto  abismo  ...  ymuy  you  youtube  ypor  yreino  yumbo  \\\n",
       "0               3       2  ...     1    0        0     0       1      0   \n",
       "1               5       0  ...     0    1        0     1       0      0   \n",
       "2               1       0  ...     0    0        0     0       0      0   \n",
       "3               2       0  ...     0    0        1     0       0      3   \n",
       "\n",
       "original  zaragoza  zelanda  zona  zonda  \n",
       "0                1        0     0      1  \n",
       "1                0        0    10      0  \n",
       "2                0        0     5      0  \n",
       "3                0        1     4      0  \n",
       "\n",
       "[4 rows x 4461 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer=CountVectorizer(stop_words=stopwords_sp,lowercase=True,ngram_range=(1,1));\n",
    "\n",
    "vectorizer.fit(textos_limpios);\n",
    "\n",
    "feature_names = pd.DataFrame()\n",
    "\n",
    "if len(vectorizer.get_feature_names()[0].split(' '))==2:\n",
    "    aux = pd.Series(vectorizer.get_feature_names())\n",
    "    aux = aux.str.split(' ',expand=True)\n",
    "    aux.columns= ['word1','word2']\n",
    "    aux = aux.merge(stem_match,how='left', left_on='word1',right_on='stem')\n",
    "    aux = aux.merge(stem_match,how='left', left_on='word2',right_on='stem',suffixes=('_1','_2'))\n",
    "    features_names= aux['original_1']+\" \"+aux['original_2']\n",
    "\n",
    "else:\n",
    "    aux = pd.DataFrame(vectorizer.get_feature_names())\n",
    "    aux.columns=['word1']\n",
    "    features_names= aux.merge(stem_match, how='left',left_on='word1',right_on='stem')['original']\n",
    "    \n",
    "\n",
    "CV_encoding=vectorizer.transform(textos_limpios);\n",
    "pd.DataFrame(CV_encoding.todense(),columns=features_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>original</th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aahora</th>\n",
       "      <th>abajo</th>\n",
       "      <th>abasto</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>abdominales</th>\n",
       "      <th>abertis</th>\n",
       "      <th>abierto</th>\n",
       "      <th>abismo</th>\n",
       "      <th>...</th>\n",
       "      <th>ymuy</th>\n",
       "      <th>you</th>\n",
       "      <th>youtube</th>\n",
       "      <th>ypor</th>\n",
       "      <th>yreino</th>\n",
       "      <th>yumbo</th>\n",
       "      <th>zaragoza</th>\n",
       "      <th>zelanda</th>\n",
       "      <th>zona</th>\n",
       "      <th>zonda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017495</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008685</td>\n",
       "      <td>0.011095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005548</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005548</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005548</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004723</td>\n",
       "      <td>0.012323</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030146</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005787</td>\n",
       "      <td>0.011089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005787</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035390</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004920</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004714</td>\n",
       "      <td>0.003716</td>\n",
       "      <td>0.009427</td>\n",
       "      <td>0.004714</td>\n",
       "      <td>0.009427</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004920</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014141</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004714</td>\n",
       "      <td>0.012035</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 4461 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "original        aa       aaa    aahora     abajo    abasto   abdomen  \\\n",
       "0         0.002895  0.000000  0.000000  0.017495  0.000000  0.000000   \n",
       "1         0.002465  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2         0.005787  0.011089  0.000000  0.000000  0.000000  0.000000   \n",
       "3         0.004920  0.000000  0.004714  0.003716  0.009427  0.004714   \n",
       "\n",
       "original  abdominales   abertis   abierto    abismo  ...      ymuy       you  \\\n",
       "0            0.000000  0.000000  0.008685  0.011095  ...  0.005548  0.000000   \n",
       "1            0.000000  0.004723  0.012323  0.000000  ...  0.000000  0.004723   \n",
       "2            0.000000  0.000000  0.005787  0.000000  ...  0.000000  0.000000   \n",
       "3            0.009427  0.000000  0.004920  0.000000  ...  0.000000  0.000000   \n",
       "\n",
       "original   youtube      ypor    yreino     yumbo  zaragoza   zelanda  \\\n",
       "0         0.000000  0.000000  0.005548  0.000000  0.005548  0.000000   \n",
       "1         0.000000  0.004723  0.000000  0.000000  0.000000  0.000000   \n",
       "2         0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3         0.004714  0.000000  0.000000  0.014141  0.000000  0.004714   \n",
       "\n",
       "original      zona     zonda  \n",
       "0         0.000000  0.005548  \n",
       "1         0.030146  0.000000  \n",
       "2         0.035390  0.000000  \n",
       "3         0.012035  0.000000  \n",
       "\n",
       "[4 rows x 4461 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tfidf_encoding=TfidfTransformer().fit_transform(CV_encoding);\n",
    "pd.DataFrame(Tfidf_encoding.todense(),columns=features_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd=TruncatedSVD(n_components=10);\n",
    "P=svd.fit_transform(Tfidf_encoding)\n",
    "\n",
    "# color = ['b','g','r','c']\n",
    "# plt.figure()\n",
    "# patches = []\n",
    "\n",
    "# P = pd.DataFrame(P)\n",
    "# P.iloc[:,0:2]\n",
    "# i=0\n",
    "# for texto in file.unique():\n",
    "#     mask= file==texto\n",
    "#     plt.plot(P.loc[mask,0], P.loc[mask,1], color[i]+\"o\", label=''.join(file[mask]))\n",
    "#     i=i+1\n",
    "\n",
    "# plt.legend()\n",
    "# plt.xlabel('dimension 1')\n",
    "# plt.ylabel('dimension 2')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             aa\n",
       "1            aaa\n",
       "2         aahora\n",
       "3          abajo\n",
       "4         abasto\n",
       "          ...   \n",
       "4456       yumbo\n",
       "4457    zaragoza\n",
       "4458     zelanda\n",
       "4459        zona\n",
       "4460       zonda\n",
       "Name: original, Length: 4461, dtype: object"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Principales componentes:\n",
      "comp_0: bueno,mas,si,hace,tambien,puede,paso,ahora,caso,hablando,dice,quiero,argentina,estan,cuarentena\n",
      "\n",
      "comp_1: supermercado,clinica,abrir,puede,policia,imagen,nico,franco,pagar\n",
      "\n",
      "comp_2: cobrar,cuarentena,frontera,provincia,tambien,situacion\n",
      "\n",
      "comp_3: mas,hace,convocando,va,van\n",
      "\n"
     ]
    }
   ],
   "source": [
    "componentes_SVD=pd.DataFrame(features_names)\n",
    "componentes_SVD.columns=['feature']\n",
    "for i in range(0,len(svd.components_)):\n",
    "    componentes_SVD = componentes_SVD.join(pd.DataFrame(svd.components_[i],columns=['comp_'+str(i)]))\n",
    "\n",
    "print(\"Principales componentes:\")\n",
    "for x in componentes_SVD.drop(columns=['feature']).columns:\n",
    "    aux=componentes_SVD.sort_values(by=[x],ascending=False)\n",
    "    mask=componentes_SVD[x]>0.10\n",
    "    aux=aux.loc[mask,:]\n",
    "    print(x+\":\",','.join(aux['feature'][0:15]))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "prueba = pd.DataFrame(Tfidf_encoding.todense(),columns=features_names)\n",
    "prueba.index = file\n",
    "prueba= prueba.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C5N-8-11\n",
      "original\n",
      "mas        0.234492\n",
      "hace       0.211332\n",
      "bueno      0.208437\n",
      "si         0.208437\n",
      "paso       0.167908\n",
      "habia      0.141853\n",
      "tambien    0.136063\n",
      "dice       0.133168\n",
      "dos        0.130273\n",
      "mentira    0.126840\n",
      "Name: C5N-8-11, dtype: float64\n",
      "\n",
      "C5N-8-14\n",
      "original\n",
      "mas           0.300684\n",
      "hace          0.248927\n",
      "si            0.243998\n",
      "bueno         0.214423\n",
      "tambien       0.194706\n",
      "caso          0.157736\n",
      "puede         0.138019\n",
      "cuarentena    0.120767\n",
      "va            0.120767\n",
      "paso          0.118302\n",
      "Name: C5N-8-14, dtype: float64\n",
      "\n",
      "TN-8-11\n",
      "original\n",
      "bueno       0.225680\n",
      "si          0.208320\n",
      "puede       0.202533\n",
      "mas         0.179387\n",
      "tambien     0.162027\n",
      "hablando    0.150453\n",
      "hace        0.150453\n",
      "paso        0.144667\n",
      "quiero      0.138880\n",
      "dice        0.127307\n",
      "Name: TN-8-11, dtype: float64\n",
      "\n",
      "TN-8-14\n",
      "original\n",
      "bueno         0.290251\n",
      "tambien       0.223838\n",
      "si            0.199240\n",
      "mas           0.196781\n",
      "puede         0.169723\n",
      "ahora         0.164804\n",
      "hace          0.159884\n",
      "cuarentena    0.154965\n",
      "argentina     0.150045\n",
      "caso          0.145126\n",
      "Name: TN-8-14, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in prueba.columns:\n",
    "    print(x)\n",
    "    print(prueba[x].sort_values(ascending=False)[0:10])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>original</th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aahora</th>\n",
       "      <th>abajo</th>\n",
       "      <th>abasto</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>abdominales</th>\n",
       "      <th>abertis</th>\n",
       "      <th>abierto</th>\n",
       "      <th>abismo</th>\n",
       "      <th>...</th>\n",
       "      <th>ymuy</th>\n",
       "      <th>you</th>\n",
       "      <th>youtube</th>\n",
       "      <th>ypor</th>\n",
       "      <th>yreino</th>\n",
       "      <th>yumbo</th>\n",
       "      <th>zaragoza</th>\n",
       "      <th>zelanda</th>\n",
       "      <th>zona</th>\n",
       "      <th>zonda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>C5N-8-11</th>\n",
       "      <td>0.002895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017495</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008685</td>\n",
       "      <td>0.011095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005548</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005548</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005548</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C5N-8-14</th>\n",
       "      <td>0.002465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004723</td>\n",
       "      <td>0.012323</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030146</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TN-8-11</th>\n",
       "      <td>0.005787</td>\n",
       "      <td>0.011089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005787</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035390</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TN-8-14</th>\n",
       "      <td>0.004920</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004714</td>\n",
       "      <td>0.003716</td>\n",
       "      <td>0.009427</td>\n",
       "      <td>0.004714</td>\n",
       "      <td>0.009427</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004920</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014141</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004714</td>\n",
       "      <td>0.012035</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 4461 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "original        aa       aaa    aahora     abajo    abasto   abdomen  \\\n",
       "C5N-8-11  0.002895  0.000000  0.000000  0.017495  0.000000  0.000000   \n",
       "C5N-8-14  0.002465  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "TN-8-11   0.005787  0.011089  0.000000  0.000000  0.000000  0.000000   \n",
       "TN-8-14   0.004920  0.000000  0.004714  0.003716  0.009427  0.004714   \n",
       "\n",
       "original  abdominales   abertis   abierto    abismo  ...      ymuy       you  \\\n",
       "C5N-8-11     0.000000  0.000000  0.008685  0.011095  ...  0.005548  0.000000   \n",
       "C5N-8-14     0.000000  0.004723  0.012323  0.000000  ...  0.000000  0.004723   \n",
       "TN-8-11      0.000000  0.000000  0.005787  0.000000  ...  0.000000  0.000000   \n",
       "TN-8-14      0.009427  0.000000  0.004920  0.000000  ...  0.000000  0.000000   \n",
       "\n",
       "original   youtube      ypor    yreino     yumbo  zaragoza   zelanda  \\\n",
       "C5N-8-11  0.000000  0.000000  0.005548  0.000000  0.005548  0.000000   \n",
       "C5N-8-14  0.000000  0.004723  0.000000  0.000000  0.000000  0.000000   \n",
       "TN-8-11   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "TN-8-14   0.004714  0.000000  0.000000  0.014141  0.000000  0.004714   \n",
       "\n",
       "original      zona     zonda  \n",
       "C5N-8-11  0.000000  0.005548  \n",
       "C5N-8-14  0.030146  0.000000  \n",
       "TN-8-11   0.035390  0.000000  \n",
       "TN-8-14   0.012035  0.000000  \n",
       "\n",
       "[4 rows x 4461 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
